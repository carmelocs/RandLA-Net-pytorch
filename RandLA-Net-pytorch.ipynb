{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c360f7f21a72e5083ad62d0bcf8bfd45b1ab32f2b7b7db5d7b0dd8bb45545b1c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Reading note for \"RandLA-Net\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_points_kernels import knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "rand_idx: [69 15  5 77  6 97 25 89 33 12]\n"
     ]
    }
   ],
   "source": [
    "rand_idx = np.random.choice(100, 10)\n",
    "print(f\"rand_idx: {rand_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pc: torch.Size([8, 1024, 7])\npc_xyz: torch.Size([8, 1024, 3])\npc_feat: torch.Size([8, 1024, 4])\n"
     ]
    }
   ],
   "source": [
    "# fake data\n",
    "torch.manual_seed(0)\n",
    "\n",
    "BATCH = 8\n",
    "NUM_POINT = 2**10\n",
    "D_XYZ = 3\n",
    "D_IN = 4\n",
    "NUM_NEIGHBOUR = 16\n",
    "\n",
    "pc = torch.rand(BATCH, NUM_POINT, D_XYZ + D_IN)\n",
    "print(f\"pc: {pc.shape}\")\n",
    "pc_xyz = pc[:, :, :3]\n",
    "print(f\"pc_xyz: {pc_xyz.shape}\")\n",
    "pc_feat = pc[:, :, 3:]\n",
    "print(f\"pc_feat: {pc_feat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "permutation min: 0\npermutation max: 99\nxyz_perm: torch.Size([8, 100, 3])\n"
     ]
    }
   ],
   "source": [
    "permutation = torch.randperm(100)\n",
    "print(f\"permutation min: {permutation.min()}\\npermutation max: {permutation.max()}\")\n",
    "xyz_perm = pc_xyz[:,permutation]\n",
    "print(f\"xyz_perm: {xyz_perm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "idx: torch.Size([8, 1000, 1])\n"
     ]
    }
   ],
   "source": [
    "idx, dist = knn(pc_xyz[:, :100].cpu().contiguous(), pc_xyz[:, :1000].cpu().contiguous(), 1)\n",
    "print(f\"idx: {idx.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended_idx = idx.unsqueeze(1).repeat(1, 3, 1, 1)\n",
    "# print(f\"extended_idx: {extended_idx.shape}\")\n",
    "# extended_dist = dist.unsqueeze(1).repeat(1, 3, 1, 1)\n",
    "# print(f\"extended_dist: {extended_dist.shape}\")\n",
    "# extended_xyz = pc_xyz.transpose(-2, -1).unsqueeze(-1).repeat(1, 1, 1, NUM_NEIGHBOUR)\n",
    "# print(f\"extended_xyz: {extended_xyz.shape}\")\n",
    "# neighbour = extended_xyz.gather(dim=2, index=extended_idx)\n",
    "# print(f\"neighbour: {neighbour.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in, d_out, kernel_size=1, stride=1, bn=False, activation_fn=None):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=d_in, out_channels=d_out, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(d_out) if bn else None\n",
    "        self.activation_fn = activation_fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x: [B, d_in, N, K]\n",
    "        Output:\n",
    "            x: [B, d_out, N, K]\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.activation_fn is not None:\n",
    "            x = self.activation_fn(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalSpatialEncoding(nn.Module):\n",
    "    def __init__(self, d_out):\n",
    "        super(LocalSpatialEncoding, self).__init__()\n",
    "\n",
    "        self.mlp = MLP(d_in=3+3+3+1, d_out=d_out, bn=True, activation_fn=nn.ReLU())\n",
    "\n",
    "    def forward(self, feat, xyz, knn_output):\n",
    "        '''\n",
    "        Input:\n",
    "            feat: [B, d_in, N, 1]\n",
    "            xyz: [B, N, 3]\n",
    "            knn_output: [B, N, K]\n",
    "        Output:\n",
    "            neighbouring_feat: [B, 2*d_out, N, K]\n",
    "\n",
    "        '''\n",
    "\n",
    "        idx, dist = knn_output  # [B, N, K]\n",
    "        B, N, K = idx.size()\n",
    "\n",
    "        extended_idx = idx.unsqueeze(1).repeat(1, 3, 1, 1)  # [B, 3, N, K]\n",
    "        extended_xyz = xyz.transpose(-2, -1).unsqueeze(-1).repeat(1, 1, 1, K)  # [B, 3, N, K]\n",
    "        neighbour = extended_xyz.gather(dim=2, index=extended_idx)  # [B, 3, N, K]\n",
    "        concat_xyz = torch.cat((extended_xyz, neighbour, extended_xyz - neighbour, dist.unsqueeze(1)), dim=1) # [B, 10, N, K]\n",
    "        relative_pnt_pos_enc = self.mlp(concat_xyz)  # [B, d_out, N, K]\n",
    "        output = torch.cat((relative_pnt_pos_enc, feat.repeat(1, 1, 1, K)), dim=1)  # [B, 2*d_out, N, K]\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LoSE features: torch.Size([8, 8, 1024, 16])\n"
     ]
    }
   ],
   "source": [
    "LoSE = LocalSpatialEncoding(d_out=4)\n",
    "knn_output = knn(pc_xyz.cpu().contiguous(), pc_xyz.cpu().contiguous(), NUM_NEIGHBOUR)\n",
    "lose_feat = LoSE(pc_feat.transpose(-2,-1).unsqueeze(-1), pc_xyz, knn_output)\n",
    "print(f\"LoSE features: {lose_feat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentivePooling(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super(AttentivePooling, self).__init__()\n",
    "\n",
    "        self.score_fn = nn.Sequential(\n",
    "            nn.Linear(d_in, d_in),\n",
    "            nn.Softmax(dim=-2)\n",
    "        )\n",
    "\n",
    "        self.mlp = MLP(d_in=d_in, d_out=d_out)\n",
    "\n",
    "    def forward(self, feat):\n",
    "        '''\n",
    "        Input:\n",
    "            feat: [B, d_in, N, K]\n",
    "        Output:\n",
    "            agg_feat: [B, d_out, N, 1]\n",
    "        '''\n",
    "        scores = self.score_fn(feat.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)  # [B, N, K, d_in] -> [B, d_in, N, K]\n",
    "        feat = torch.sum(scores*feat, dim=-1, keepdim=True)  # [B, d_in, N, 1]\n",
    "        agg_feat = self.mlp(feat)  # [B, d_out, N, 1]\n",
    "\n",
    "        return agg_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "aggregated features: torch.Size([8, 32, 1024, 1])\n"
     ]
    }
   ],
   "source": [
    "AttPooling = AttentivePooling(d_in=2*D_IN, d_out=32)\n",
    "agg_feat = AttPooling(lose_feat)\n",
    "print(f\"aggregated features: {agg_feat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalFeatureAggregation(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_neighbours):\n",
    "        super(LocalFeatureAggregation, self).__init__()\n",
    "\n",
    "        self.num_neighbours = num_neighbours\n",
    "\n",
    "        self.mlp1 = MLP(d_in=d_in, d_out=d_out//2)\n",
    "        self.mlp2 = MLP(d_in=d_out, d_out=2*d_out)\n",
    "        self.mlp3 = MLP(d_in=d_in, d_out=2*d_out, bn=True)\n",
    "\n",
    "        self.lose1 = LocalSpatialEncoding(d_out=d_out//2)\n",
    "        self.lose2 = LocalSpatialEncoding(d_out=d_out//2)\n",
    "\n",
    "        self.pool1 = AttentivePooling(d_in=d_out, d_out=d_out//2)\n",
    "        self.pool2 = AttentivePooling(d_in=d_out, d_out=d_out)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, feat, xyz):\n",
    "        '''\n",
    "        Input:\n",
    "            feat: [B, d_in, N, 1]\n",
    "            xyz: [B, N, 3]\n",
    "        Output:\n",
    "            aggregated_feat: [B, N, 2*d_out]\n",
    "        '''\n",
    "        knn_output = knn(xyz.cpu().contiguous(), xyz.cpu().contiguous(), self.num_neighbours)  # [B, N, K]\n",
    "\n",
    "        residual = self.mlp3(feat)  # [B, 2*d_out, N, 1]\n",
    "\n",
    "        feat1 = self.mlp1(feat)  # [B, d_out//2, N, 1]\n",
    "        lose_feat1 = self.lose1(feat1, xyz, knn_output)  # [B, d_out, N, K]\n",
    "        att_feat1 = self.pool1(lose_feat1)  # [B, d_out//2, N, 1]\n",
    "\n",
    "        lose_feat2 = self.lose2(att_feat1, xyz, knn_output)  # [B, d_out, N, K]\n",
    "        att_feat2 = self.pool2(lose_feat2)  # [B, d_out, N, 1]\n",
    "        \n",
    "        feat2 = self.mlp2(att_feat2)  # [B, 2*d_out, N, 1]\n",
    "\n",
    "        return self.lrelu(feat2 + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregated feat: torch.Size([8, 32, 1024, 1])\n"
     ]
    }
   ],
   "source": [
    "lfa = LocalFeatureAggregation(d_in=D_IN, d_out=16, num_neighbours=NUM_NEIGHBOUR)\n",
    "aggregated_feat = lfa(pc_feat.transpose(-2,-1).unsqueeze(-1), pc_xyz)\n",
    "print(f\"Aggregated feat: {aggregated_feat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandLANet(nn.Module):\n",
    "    def __init__(self, d_in, num_classes, num_neighbours=16, decimation=4, dropout=0.5):\n",
    "        super(RandLANet, self).__init__()\n",
    "\n",
    "        self.num_neighbours = num_neighbours\n",
    "        self.decimation = decimation\n",
    "        self.fc1 = nn.Linear(in_features=d_in, out_features=8)\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            LocalFeatureAggregation(d_in=8, d_out=16, num_neighbours=num_neighbours),\n",
    "            LocalFeatureAggregation(2*16, 64, num_neighbours),\n",
    "            LocalFeatureAggregation(2*64, 128, num_neighbours),\n",
    "            LocalFeatureAggregation(2*128, 256, num_neighbours)\n",
    "        ])\n",
    "\n",
    "        self.mlp = MLP(d_in=512, d_out=512, activation_fn=nn.ReLU())\n",
    "\n",
    "        self.decoder = nn.ModuleList([\n",
    "            MLP(d_in=512, d_out=256, bn=True, activation_fn=nn.ReLU()),\n",
    "            MLP(d_in=2*256, d_out=128, bn=True, activation_fn=nn.ReLU()),\n",
    "            MLP(d_in=2*128, d_out=32, bn=True, activation_fn=nn.ReLU()),\n",
    "            MLP(d_in=2*32, d_out=8, bn=True, activation_fn=nn.ReLU())\n",
    "        ])\n",
    "\n",
    "        self.fc_final = nn.Sequential(\n",
    "            MLP(d_in=8+8, d_out=64, bn=True, activation_fn=nn.ReLU()),\n",
    "            MLP(d_in=64, d_out=32, bn=True, activation_fn=nn.ReLU()),\n",
    "            nn.Dropout(p=dropout),\n",
    "            MLP(d_in=32, d_out=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, points):\n",
    "        '''\n",
    "        Input:\n",
    "            points: [B, N, 3+d_in]\n",
    "        Output:\n",
    "            class scores: [B, num_classes, N]\n",
    "        '''\n",
    "\n",
    "        B, N, _ = points.size()\n",
    "        d = self.decimation\n",
    "        decimation_ratio = 1\n",
    "\n",
    "        xyz = points[..., :3]  # [B, N, 3]\n",
    "\n",
    "        feat_stack = []\n",
    "\n",
    "        feat = self.fc1(points).transpose(-2, -1).unsqueeze(-1)  # [B, 8, N, 1]\n",
    "\n",
    "        for lfa in self.encoder:\n",
    "            feat_stack.append(feat)\n",
    "            decimation_ratio *= d\n",
    "            feat = lfa(feat[:, :, :N//decimation_ratio], xyz[:, :N//decimation_ratio])  # [B, 2*d_out, N//decimation_ratio, 1]\n",
    "        # [B, 512, N//256, 1]\n",
    "\n",
    "        feat = self.mlp(feat)  # [B, 512, N//256, 1]\n",
    "\n",
    "        for mlp in self.decoder:\n",
    "            feat = mlp(feat)\n",
    "            # find one nearset neighbour for each upsampled point in the downsampled set\n",
    "            idx, _ = knn(xyz[:, :N//decimation_ratio].contiguous(), xyz[:,:d*N//decimation_ratio].contiguous(), 1)  # [B, d*N//decimation, 1]\n",
    "            extended_idx = idx.unsqueeze(1).repeat(1, feat.size(1), 1, 1)  # [B, d_out, d*N//decimation, 1]\n",
    "            print(f\"extended_idx: {extended_idx.shape}\")\n",
    "            feat_neighbour = torch.gather(feat, -2, extended_idx)  # [B, d_out, d*N//decimation, 1]\n",
    "            print(f\"feat_neighbour: {feat_neighbour.shape}\")\n",
    "            feat_pop = feat_stack.pop()  # [B, d_out, d*N//decimation, 1]\n",
    "            print(f\"feat_pop: {feat_pop.shape}\")\n",
    "            feat = torch.cat((feat_neighbour, feat_pop), dim=1)\n",
    "            # feat = mlp(feat)\n",
    "            decimation_ratio //= d\n",
    "        \n",
    "        scores = self.fc_final(feat)  # [B, num_classes, N, 1]\n",
    "\n",
    "        return scores.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "extended_idx: torch.Size([8, 256, 16, 1])\nfeat_neighbour: torch.Size([8, 256, 16, 1])\nfeat_pop: torch.Size([8, 256, 16, 1])\nextended_idx: torch.Size([8, 128, 64, 1])\nfeat_neighbour: torch.Size([8, 128, 64, 1])\nfeat_pop: torch.Size([8, 128, 64, 1])\nextended_idx: torch.Size([8, 32, 256, 1])\nfeat_neighbour: torch.Size([8, 32, 256, 1])\nfeat_pop: torch.Size([8, 32, 256, 1])\nextended_idx: torch.Size([8, 8, 1024, 1])\nfeat_neighbour: torch.Size([8, 8, 1024, 1])\nfeat_pop: torch.Size([8, 8, 1024, 1])\nclass scores: torch.Size([8, 40, 1024])\nclass label: torch.Size([8, 1024])\n"
     ]
    }
   ],
   "source": [
    "model = RandLANet(d_in=D_XYZ+D_IN, num_classes=40, num_neighbours=4)\n",
    "class_scores = model(pc)\n",
    "print(f\"class scores: {class_scores.shape}\")\n",
    "class_label = class_scores.transpose(-2, -1).max(-1)\n",
    "print(f\"class label: {class_label[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}